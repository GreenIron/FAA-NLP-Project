{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import STC dataset with text exported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_stc = pd.read_excel(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\stc.xlsx\")\n",
    "df_stc = df_stc.drop_duplicates()\n",
    "df_stc['drs:stcHolder'] = df_stc['drs:stcHolder'].map(lambda x: x.replace(\", Inc.\",\"\").replace(\", Inc\",\"\").replace(\" Inc.\",\"\").replace(\" Inc\",\"\"))\n",
    "\n",
    "print(df_stc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 28180 datasets currently available on the hub\n",
      "The first 10 are: ['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus', 'ag_news', 'ai2_arc', 'air_dialogue', 'ajgt_twitter_ar', 'allegro_reviews']\n"
     ]
    }
   ],
   "source": [
    "from datasets import list_datasets\n",
    "\n",
    "all_datasets = list_datasets()\n",
    "print(f\"There are {len(all_datasets)} datasets currently available on the hub\")\n",
    "print(f\"The first 10 are: {all_datasets[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: emotion/split\n",
      "Found cached dataset emotion (C:/Users/victor/.cache/huggingface/datasets/emotion/split/1.0.0/cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ebceab8e604c5da0eecaebf232cd9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "emotions = load_dataset(\"emotion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 16000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = emotions[\"train\"]\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "emotions.set_format(type=\"pandas\")\n",
    "df = emotions[\"train\"][:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name\n",
       "0                            i didnt feel humiliated      0    sadness\n",
       "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
       "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
       "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
       "4                               i am feeling grouchy      3      anger"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_int2str(row):\n",
    "    return emotions[\"train\"].features[\"label\"].int2str(row)\n",
    "\n",
    "df[\"label_name\"] = df[\"label\"].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting  the last hidden states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983ba5e9335948079b2f3fc1f1180d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\victor\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc0024708d44e5d85cede3de36ba5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34167cac9b2446cf9f52c11833b2e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i didnt feel humiliated',\n",
       " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions[\"train\"][:2][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(emotions[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(tokenize(emotions[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m][:\u001b[39m2\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m, in \u001b[0;36mtokenize\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(batch):\n\u001b[1;32m----> 2\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer(batch[\u001b[39m\"\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m\"\u001b[39;49m], padding\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, truncation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2530\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2528\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2529\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2530\u001b[0m     encodings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_one(text\u001b[39m=\u001b[39mtext, text_pair\u001b[39m=\u001b[39mtext_pair, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mall_kwargs)\n\u001b[0;32m   2531\u001b[0m \u001b[39mif\u001b[39;00m text_target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2532\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2588\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2585\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   2587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[1;32m-> 2588\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2589\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2590\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2591\u001b[0m     )\n\u001b[0;32m   2593\u001b[0m \u001b[39mif\u001b[39;00m text_pair \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[0;32m   2594\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2595\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext input must of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2596\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2597\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "print(tokenize(emotions[\"train\"][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\victor\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-0027efc2c2373cce.arrow\n",
      "Loading cached processed dataset at C:\\Users\\victor\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-7b8825fc9a57184a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\victor\\.cache\\huggingface\\datasets\\emotion\\split\\1.0.0\\cca5efe2dfeb58c1d098e0f9eeb200e9927d889b5a03c67097275dfb5fe463bd\\cache-65719b47f3acde1b.arrow\n"
     ]
    }
   ],
   "source": [
    "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2023, 2003, 1037, 3231, 102], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'this', 'is', 'a', 'test', '[SEP]']\n",
      "Input tensor shape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "text = \"this is a test\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "encoded_text = tokenizer(text)\n",
    "print(encoded_text)\n",
    "print(tokenizer.convert_ids_to_tokens(encoded_text[\"input_ids\"]))\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutput(last_hidden_state=tensor([[[-0.1565, -0.1862,  0.0528,  ..., -0.1188,  0.0662,  0.5470],\n",
      "         [-0.3575, -0.6484, -0.0618,  ..., -0.3040,  0.3508,  0.5221],\n",
      "         [-0.2772, -0.4459,  0.1818,  ..., -0.0948, -0.0076,  0.9958],\n",
      "         [-0.2841, -0.3917,  0.3753,  ..., -0.2151, -0.1173,  1.0526],\n",
      "         [ 0.2661, -0.5094, -0.3180,  ..., -0.4203,  0.0144, -0.2149],\n",
      "         [ 0.9441,  0.0112, -0.4714,  ...,  0.1439, -0.7288, -0.1619]]],\n",
      "       device='cuda:0'), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 768])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state[:,0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    # Extract last hidden states\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_encoded.set_format(\"torch\",\n",
    "                            columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0572c43897e04e93be95a30eb904e6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb2e351b7aa47a6b8fedd9a880ecb77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cda820c14a4ff791cb3a3aa2f5cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "emotions_hidden = emotions_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'label', 'input_ids', 'attention_mask', 'hidden_state']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotions_hidden[\"train\"].column_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 768), (2000, 768))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array(emotions_hidden[\"train\"][\"hidden_state\"])\n",
    "X_valid = np.array(emotions_hidden[\"validation\"][\"hidden_state\"])\n",
    "y_train = np.array(emotions_hidden[\"train\"][\"label\"])\n",
    "y_valid = np.array(emotions_hidden[\"validation\"][\"label\"])\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.043881</td>\n",
       "      <td>6.360016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.214177</td>\n",
       "      <td>5.473805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.975804</td>\n",
       "      <td>2.998239</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.322908</td>\n",
       "      <td>3.223631</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.533185</td>\n",
       "      <td>3.304369</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y  emb\n",
       "0  4.043881  6.360016    0\n",
       "1 -3.214177  5.473805    0\n",
       "2  4.975804  2.998239    3\n",
       "3 -2.322908  3.223631    2\n",
       "4 -3.533185  3.304369    3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Scale features [0,1] range\n",
    "X_scaled = MinMaxScaler().fit_transform(X_train)\n",
    "# Initialize and fit UMAP\n",
    "mapper = UMAP(n_components=2, metric=\"cosine\").fit(X_scaled)\n",
    "# Create a Dataframe of 2D embeddings\n",
    "df_emb = pd.DataFrame(mapper.embedding_, columns=[\"X\", \"Y\"])\n",
    "df_emb[\"emb\"] = y_train\n",
    "df_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\scope.py:198\u001b[0m, in \u001b[0;36mScope.resolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_resolvers:\n\u001b[1;32m--> 198\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresolvers[key]\n\u001b[0;32m    200\u001b[0m \u001b[39m# if we're here that means that we have no locals and we also have\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m# no resolvers\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\collections\\__init__.py:941\u001b[0m, in \u001b[0;36mChainMap.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m         \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 941\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__missing__\u001b[39;49m(key)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\collections\\__init__.py:933\u001b[0m, in \u001b[0;36mChainMap.__missing__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__missing__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m--> 933\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\scope.py:209\u001b[0m, in \u001b[0;36mScope.resolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[39m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[39m# e.g., df[df > 0]\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemps[key]\n\u001b[0;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUndefinedVariableError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m labels \u001b[39m=\u001b[39m emotions[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfeatures[\u001b[39m\"\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mnames\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m i, (label, cmap) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(labels, cmaps)):\n\u001b[1;32m----> 9\u001b[0m     df_emb_sub \u001b[39m=\u001b[39m df_emb\u001b[39m.\u001b[39;49mquery(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlabel == \u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     10\u001b[0m     \u001b[39m#axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap, gridsize=20, linewidths=(0,))\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[39m#axes[i].set_title(label)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[39m#axes[i].set_xticks([]), axes[i].set_yticks([])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\frame.py:4474\u001b[0m, in \u001b[0;36mDataFrame.query\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4472\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m   4473\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 4474\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval(expr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   4476\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   4477\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[res]\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\frame.py:4612\u001b[0m, in \u001b[0;36mDataFrame.eval\u001b[1;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[0;32m   4609\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[0;32m   4610\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mresolvers\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresolvers\u001b[39m\u001b[39m\"\u001b[39m, ())) \u001b[39m+\u001b[39m resolvers\n\u001b[1;32m-> 4612\u001b[0m \u001b[39mreturn\u001b[39;00m _eval(expr, inplace\u001b[39m=\u001b[39minplace, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\eval.py:353\u001b[0m, in \u001b[0;36meval\u001b[1;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[39m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[0;32m    345\u001b[0m env \u001b[39m=\u001b[39m ensure_scope(\n\u001b[0;32m    346\u001b[0m     level \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m,\n\u001b[0;32m    347\u001b[0m     global_dict\u001b[39m=\u001b[39mglobal_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    350\u001b[0m     target\u001b[39m=\u001b[39mtarget,\n\u001b[0;32m    351\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m parsed_expr \u001b[39m=\u001b[39m Expr(expr, engine\u001b[39m=\u001b[39;49mengine, parser\u001b[39m=\u001b[39;49mparser, env\u001b[39m=\u001b[39;49menv)\n\u001b[0;32m    355\u001b[0m \u001b[39m# construct the engine and evaluate the parsed expression\u001b[39;00m\n\u001b[0;32m    356\u001b[0m eng \u001b[39m=\u001b[39m ENGINES[engine]\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:813\u001b[0m, in \u001b[0;36mExpr.__init__\u001b[1;34m(self, expr, engine, parser, env, level)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser \u001b[39m=\u001b[39m parser\n\u001b[0;32m    812\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_visitor \u001b[39m=\u001b[39m PARSERS[parser](\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparser)\n\u001b[1;32m--> 813\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterms \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse()\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:832\u001b[0m, in \u001b[0;36mExpr.parse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    829\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[39m    Parse an expression.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 832\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_visitor\u001b[39m.\u001b[39;49mvisit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexpr)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:421\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Module\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mSyntaxError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39monly a single expression is allowed\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    420\u001b[0m expr \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mbody[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 421\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(expr, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:424\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Expr\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Expr\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 424\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mvalue, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:723\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Compare\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    721\u001b[0m     op \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslate_In(ops[\u001b[39m0\u001b[39m])\n\u001b[0;32m    722\u001b[0m     binop \u001b[39m=\u001b[39m ast\u001b[39m.\u001b[39mBinOp(op\u001b[39m=\u001b[39mop, left\u001b[39m=\u001b[39mnode\u001b[39m.\u001b[39mleft, right\u001b[39m=\u001b[39mcomps[\u001b[39m0\u001b[39m])\n\u001b[1;32m--> 723\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(binop)\n\u001b[0;32m    725\u001b[0m \u001b[39m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m left \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mleft\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:536\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_BinOp\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_BinOp\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 536\u001b[0m     op, op_class, left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_transform_eq_ne(node)\n\u001b[0;32m    537\u001b[0m     left, right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_downcast_constants(left, right)\n\u001b[0;32m    538\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_evaluate_binop(op, op_class, left, right)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:456\u001b[0m, in \u001b[0;36mBaseExprVisitor._maybe_transform_eq_ne\u001b[1;34m(self, node, left, right)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_transform_eq_ne\u001b[39m(\u001b[39mself\u001b[39m, node, left\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, right\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m left \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m         left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(node\u001b[39m.\u001b[39;49mleft, side\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m right \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m         right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(node\u001b[39m.\u001b[39mright, side\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mright\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:415\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    413\u001b[0m method \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvisit_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mtype\u001b[39m(node)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m    414\u001b[0m visitor \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, method)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m visitor(node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\expr.py:549\u001b[0m, in \u001b[0;36mBaseExprVisitor.visit_Name\u001b[1;34m(self, node, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_Name\u001b[39m(\u001b[39mself\u001b[39m, node, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 549\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mterm_type(node\u001b[39m.\u001b[39mid, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\ops.py:85\u001b[0m, in \u001b[0;36mTerm.__init__\u001b[1;34m(self, name, env, side, encoding)\u001b[0m\n\u001b[0;32m     83\u001b[0m tname \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(name)\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_local \u001b[39m=\u001b[39m tname\u001b[39m.\u001b[39mstartswith(LOCAL_TAG) \u001b[39mor\u001b[39;00m tname \u001b[39min\u001b[39;00m DEFAULT_GLOBALS\n\u001b[1;32m---> 85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_resolve_name()\n\u001b[0;32m     86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding \u001b[39m=\u001b[39m encoding\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\ops.py:109\u001b[0m, in \u001b[0;36mTerm._resolve_name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m local_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mscope \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mscope[local_name], \u001b[39mtype\u001b[39m\n\u001b[0;32m    106\u001b[0m ):\n\u001b[0;32m    107\u001b[0m     is_local \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mresolve(local_name, is_local\u001b[39m=\u001b[39;49mis_local)\n\u001b[0;32m    110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate(res)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(res, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m res\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\stc_text\\lib\\site-packages\\pandas\\core\\computation\\scope.py:211\u001b[0m, in \u001b[0;36mScope.resolve\u001b[1;34m(self, key, is_local)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtemps[key]\n\u001b[0;32m    210\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;31mUndefinedVariableError\u001b[0m: name 'label' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(7,5))\n",
    "axes = axes.flatten()\n",
    "cmaps = [\"Greys\", \"Blues\", \"Oranges\", \"Reds\", \"Purples\", \"Greens\"]\n",
    "labels = emotions[\"train\"].features[\"label\"].names\n",
    "\n",
    "for i, (label, cmap) in enumerate(zip(labels, cmaps)):\n",
    "    df_emb_sub = df_emb.query(f\"label == {i}\")\n",
    "    #axes[i].hexbin(df_emb_sub[\"X\"], df_emb_sub[\"Y\"], cmap=cmap, gridsize=20, linewidths=(0,))\n",
    "    #axes[i].set_title(label)\n",
    "    #axes[i].set_xticks([]), axes[i].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# We increase 'max_iter' to guarantee convergence\n",
    "lr_clf = LogisticRegression(max_iter=3000)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "dummy_clf.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "y_preds = lr_clf.predict(X_valid)\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning transformers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 6\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=num_labels)\n",
    "         .to(device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 64\n",
    "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{model_ckpt}-finetuned-emotion\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  logging_steps=logging_steps,\n",
    "                                  push_to_hub=True,\n",
    "                                  log_level=\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  args=training_args,\n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=emotions_encoded[\"train\"],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
