{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DRS document\n",
    "Defining the functions first and then applying that on a selection of suitable document types (ACs and Orders like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def get_bookmarks(outlines, pdf, parent_position_in_bookmark_tree):\n",
    "\n",
    "    def get_bookmark_content(outline, pdf): # il faut améliorer le code pour pouvoir faire avanter dans la page et pas commencer le get_destination_page_number au debut. reutiliser la derniere page aussi\n",
    "        # DEBUG     \"Article. A material, part, component, process\" in outline.title\n",
    "        if pdf.get_destination_page_number(outline)>=0:\n",
    "            try:\n",
    "                repattern_title_number_ac = 'AC 2[13759]'+\\\n",
    "                                            '('+\\\n",
    "                                                '\\.[0-9]{1,5}[A-Z]?\\.?[\\s]{1,3}§'+\\\n",
    "                                                    '|'+\\\n",
    "                                                '(?= MG [0-9]{1,2}\\.?)'+\\\n",
    "                                            ')' \n",
    "                repattern_title_text_ac = '('+\\\n",
    "                                            '2[13759]\\.[0-9]{1,5}\\.?'+\\\n",
    "                                            ' (\\(A[A-Za-z 0-9-]*\\))?' +\\\n",
    "                                                    '|'+\\\n",
    "                                            'MG [0-9]{1,2}\\.?'+\\\n",
    "                                            ')'      \n",
    "                                                                                                                         \n",
    "                repattern_title_prefix = '(VOLUME|volume|Volume|Section|SECTION|section|Section|PART|SUBPART|CHAPTER|chapter|Chapter|APPENDIX|Appendix|appendix)+[\\s]{1,2}'\n",
    "                repattern_greek = '[ivx]{2,3}|[IVX]{2,3}'\n",
    "                repattern_title_prevent_firstletter_mismatch = '(?!([A-Z]{2,10}|[a-z]{2,10}))'    \n",
    "                repattern_title_number_basic = '[\\(]?('+repattern_greek+'|[1-9][0-9]{0,3}|[A-Za-z])'+repattern_title_prevent_firstletter_mismatch\n",
    "                repattern_title_delimiter = '(-|\\)|\\.)'\n",
    "\n",
    "                repattern_title_number ='('+\\\n",
    "                                            repattern_title_number_ac+\\\n",
    "                                        '|'+\\\n",
    "                                            '('+repattern_title_prefix+')?'+\\\n",
    "                                            '('+\\\n",
    "                                                repattern_title_delimiter.join([repattern_title_number_basic, \n",
    "                                                                                repattern_title_number_basic, \n",
    "                                                                                '[ ]?'+repattern_title_number_basic, \n",
    "                                                                                repattern_title_number_basic])+\\\n",
    "                                            '|'+\\\n",
    "                                                repattern_title_delimiter.join([repattern_title_number_basic, \n",
    "                                                                                repattern_title_number_basic, \n",
    "                                                                                '[ ]?'+repattern_title_number_basic])+\\\n",
    "                                            '|'+\\\n",
    "                                                repattern_title_delimiter.join([repattern_title_number_basic, \n",
    "                                                                                repattern_title_number_basic])+\\\n",
    "                                            '|'+\\\n",
    "                                                repattern_title_delimiter.join([repattern_title_number_basic])+\\\n",
    "                                            ')'+\\\n",
    "                                        ')'+\\\n",
    "                                        '[\\s]{0,2}'+repattern_title_delimiter+'?'+'[\\s]{0,2}'\n",
    "                \n",
    "                repattern_before_title = '(?<=( |\\n))'\n",
    "                \n",
    "                for offset in [0,-1,-2,1,2]:                \n",
    "                    line_with_title = None\n",
    "                    nb_keywords = 5\n",
    "                    while line_with_title is None and nb_keywords>0:\n",
    "                        outline_title_cleaned = re.sub('[^a-zA-Z ,/\\d\\s\\.:-]', '.', outline.title)\n",
    "\n",
    "                        title_shortened_variable_spaces = re.sub('[ ]+', ' ', outline_title_cleaned).split(' ')[:nb_keywords]\n",
    "                        title_shortened_variable_spaces = title_shortened_variable_spaces[:2]+\\\n",
    "                                                        [keyword[:2]+'-?'.join(keyword[2:]) for keyword in title_shortened_variable_spaces[2:]]\n",
    "                        title_shortened_variable_spaces = '[ ]*'.join(title_shortened_variable_spaces)\n",
    "\n",
    "                        repattern_title_line = '('+repattern_before_title+repattern_title_number+')?'+\\\n",
    "                                                title_shortened_variable_spaces+\\\n",
    "                                                '.*(\\n|\\r|$)'\n",
    "                        try:\n",
    "                            line_with_title = re.search(repattern_title_line,\n",
    "                                                        pdf.pages[max(0,pdf.get_destination_page_number(outline)+offset)].extract_text())\n",
    "                        except:\n",
    "                            pass                        \n",
    "\n",
    "                        if line_with_title is not None:\n",
    "                            break\n",
    "                        else:\n",
    "                            nb_keywords = nb_keywords - 1\n",
    "\n",
    "                    if line_with_title is not None:\n",
    "                        break\n",
    "                    \n",
    "                sentence_around_title = pdf.pages[max(0,\n",
    "                                                      pdf.get_destination_page_number(outline)+offset)].extract_text()[line_with_title.span()[0]:\\\n",
    "                                                                                                                        max(line_with_title.span()[1],\\\n",
    "                                                                                                                            line_with_title.span()[0]+len(outline.title))]\n",
    "                title_number = re.search(repattern_title_number, sentence_around_title)\n",
    "\n",
    "                title_max_length = 200\n",
    "                title_text_end_delimiter = '(\\.|\\:|\\?|\\n|\\r|$)?'\n",
    "                repattern_title_text = '('+repattern_title_text_ac+')?'+\\\n",
    "                                        '[A-Za-z,\\/\\-\\s0-1\\(\\)\\[\\]]'+\\\n",
    "                                        '{3,'+str(title_max_length)+'}'+title_text_end_delimiter# [\\s]{1,3}\n",
    "                if title_number is not None:\n",
    "                    title_text = re.search(repattern_title_text, \n",
    "                                           sentence_around_title[len(title_number.group(0)):])\n",
    "                    string_after_title = title_text.string[title_text.span()[1]:\n",
    "                                                            (title_text.span()[1]+30)]\n",
    "\n",
    "                    bookmark_content = [outline.title,\n",
    "                                        str(pdf.get_destination_page_number(outline)),\n",
    "                                        str(pdf.get_destination_page_number(outline)+offset),\n",
    "                                        title_number.group(0),\n",
    "                                        title_text.group(0),\n",
    "                                        string_after_title,\n",
    "                                        str(nb_keywords)\n",
    "                                        ]\n",
    "                    pass\n",
    "                else:\n",
    "                    title_text = re.search(repattern_title_text, sentence_around_title[len(title_number.group(0)):])\n",
    "                    string_after_title = title_text.string[title_text.span()[1]:\n",
    "                                                           (title_text.span()[1]+30)]\n",
    "\n",
    "                    bookmark_content = [outline.title,\n",
    "                                        str(pdf.get_destination_page_number(outline)),\n",
    "                                        str(pdf.get_destination_page_number(outline)+offset),\n",
    "                                        '',\n",
    "                                        title_text.group(0),\n",
    "                                        string_after_title,\n",
    "                                        str(nb_keywords)\n",
    "                                        ]\n",
    "                    pass\n",
    "            except:\n",
    "                bookmark_content = [outline.title,\n",
    "                                    pdf.get_destination_page_number(outline),\n",
    "                                    '',\n",
    "                                    '',\n",
    "                                    '',\n",
    "                                    '',\n",
    "                                    ''\n",
    "                                    ]\n",
    "                pass\n",
    "        else:\n",
    "            bookmark_content = [outline.title,\n",
    "                                pdf.get_destination_page_number(outline),\n",
    "                                '',\n",
    "                                '',\n",
    "                                '',\n",
    "                                '',\n",
    "                                ''\n",
    "                                ]\n",
    "            pass\n",
    "        \n",
    "        return bookmark_content\n",
    "\n",
    "\n",
    "    headers = ['position in bookmark tree',\n",
    "                'original pdf bookmark title (outline.title)',\n",
    "                'original pdf bookmark page number',\n",
    "                'corrected pdf bookmark page number',\n",
    "                'extracted title number',\n",
    "                'extracted title text',\n",
    "                'first 20 characters after title',\n",
    "                'nb_keywords for title search']\n",
    "\n",
    "    df_content = pd.DataFrame(columns=headers,\n",
    "                            dtype=\"string\")\n",
    "    \n",
    "    n_section = -1\n",
    "\n",
    "    for outline in outlines:\n",
    "        if type(outline) == PyPDF2.generic._data_structures.Destination:\n",
    "            n_section = n_section + 1\n",
    "            if parent_position_in_bookmark_tree=='':\n",
    "                current_position_in_bookmark_tree = str(n_section)\n",
    "            else:\n",
    "                current_position_in_bookmark_tree = parent_position_in_bookmark_tree+'>'+str(n_section)\n",
    "\n",
    "            df_thisbookmark_content = get_bookmark_content(outline, pdf)\n",
    "            df_thisbookmark_content = [current_position_in_bookmark_tree]+df_thisbookmark_content\n",
    "\n",
    "            try:\n",
    "                df_thisbookmark_content = pd.DataFrame(dict(zip(headers, df_thisbookmark_content)),\n",
    "                                                    dtype=\"string\", \n",
    "                                                    index=[0])\n",
    "            except UnicodeDecodeError:\n",
    "                df_thisbookmark_content[1] = df_thisbookmark_content[1].decode('utf-8','ignore')+' (Python Exception: title UnicodeDecodeError)'\n",
    "                df_thisbookmark_content = pd.DataFrame(dict(zip(headers, df_thisbookmark_content)),\n",
    "                                                    dtype=\"string\", \n",
    "                                                    index=[0])\n",
    "\n",
    "            df_content = pd.concat([df_content, \n",
    "                                    df_thisbookmark_content], \n",
    "                                    ignore_index=True)\n",
    "        elif type(outline) == list:\n",
    "            if parent_position_in_bookmark_tree=='':\n",
    "                current_position_in_bookmark_tree = str(n_section)\n",
    "            else:\n",
    "                current_position_in_bookmark_tree = parent_position_in_bookmark_tree+'>'+str(n_section)\n",
    "\n",
    "            extracted_content = get_bookmarks(outline, pdf, current_position_in_bookmark_tree)\n",
    "\n",
    "            df_content = pd.concat([df_content, \n",
    "                                    extracted_content], \n",
    "                                    ignore_index=True)\n",
    "        else:\n",
    "            raise Exception\n",
    "        \n",
    "    return df_content\n",
    "\n",
    "# drs_doc = PyPDF2.PdfReader(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\raw data\\AC\\pdf\\Current__083AD53732DC0D4686258347005037DF.pdf\") # AC 43-13\n",
    "# drs_doc = PyPDF2.PdfReader(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\raw data\\AC\\pdf\\Current__99C827DB9BAAC81B86256B4500596C4E.pdf\") # AC 43-13\n",
    "# drs_doc = PyPDF2.PdfReader(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\raw data\\AC\\pdf\\Current__C7CCE9FCA6D7E34786257D41004C3E63.pdf\") # AC 29\n",
    "# drs_doc = PyPDF2.PdfReader(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\raw data\\ORDER_8900.1\\pdf\\Current__DRSDOCID166392477020230614171412.pdf\") # Order\n",
    "# drs_doc = PyPDF2.PdfReader(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\raw data\\AC\\pdf\\Current__C2774DBA5FFEE8D286258088005528A9.pdf\") # Order\n",
    "\n",
    "\n",
    "# import glob, os\n",
    "# matching_file = glob.glob(os.path.join(os.getcwd(), 'data', 'DRS', 'raw data', '**','**','*5934B72DA528D2CC862585230041269E*'))\n",
    "# drs_doc = PyPDF2.PdfReader(matching_file[0])\n",
    "\n",
    "# df_content = get_bookmarks(outlines = drs_doc.outline, pdf = drs_doc, parent_position_in_bookmark_tree='') # [8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AC 21-43A: E7E9387A5386881C86257ED9005A1B5A\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import datetime\n",
    "\n",
    "drs_doc_types = ['AC',\n",
    "                 'ORDER_8300.10',\n",
    "                 'ORDER_8400.10',\n",
    "                 'ORDER_8700.1',\n",
    "                 'ORDER_8740.1',\n",
    "                 'ORDER_8900.1',\n",
    "                 'ORDERS']\n",
    "\n",
    "df_all_content = None\n",
    "\n",
    "for drs_doc_type in drs_doc_types:\n",
    "    df_index = glob.glob(os.path.join(os.getcwd(), 'data', 'DRS', 'index', drs_doc_type+'*.parquet'))[-1]\n",
    "    df_index = pd.read_parquet(df_index)\n",
    "\n",
    "    \n",
    "    # DEBUG\n",
    "    # df_index = df_index[df_index[\"documentGuid\"]=='E7E9387A5386881C86257ED9005A1B5A']\n",
    "    # DEBUG\n",
    "\n",
    "\n",
    "    for index, row in df_index.iterrows():\n",
    "        matching_file = glob.glob(os.path.join(os.getcwd(), 'data', 'DRS', 'raw data', drs_doc_type, 'pdf','*'+row['documentGuid']+'*.pdf'))\n",
    "        if len(matching_file)>0:\n",
    "            if row['drs:status']=='Current':\n",
    "                if 'drs:docID'  in row.index:\n",
    "                    print(row['drs:docID']+': '+row['documentGuid'])\n",
    "                elif 'drs:documentNumber' in row.index:\n",
    "                    print(row['drs:documentNumber']+': '+row['documentGuid'])\n",
    "\n",
    "                drs_doc = PyPDF2.PdfReader(matching_file[0])\n",
    "                df_content = get_bookmarks(outlines = drs_doc.outline, pdf = drs_doc, parent_position_in_bookmark_tree='')\n",
    "\n",
    "                if len(df_content)>0:                    \n",
    "                    df_content.insert(loc=0, \n",
    "                                      column='documentGuid', \n",
    "                                      value=pd.Series(data=row['documentGuid'], index=df_content.index, dtype=\"string\"))\n",
    "                    if df_all_content is not None:\n",
    "                        df_all_content = pd.concat([df_all_content, \n",
    "                                                    df_content], \n",
    "                                                    ignore_index=True)\n",
    "                    else:\n",
    "                        df_all_content = df_content\n",
    "                    print('   -> '+str(df_all_content.shape))\n",
    "\n",
    "                \n",
    "df_all_content.to_parquet(os.path.join(os.getcwd(), \n",
    "                                       'data', \n",
    "                                       'DRS', \n",
    "                                       'extracted_text_for_'+'-'.join(drs_doc_types)+'-'+datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")+'.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# df_all_content = pd.read_parquet(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\extracted_text_for_AC-ORDER_8300.10-ORDER_8400.10-ORDER_8700.1-ORDER_8740.1-ORDER_8900.1-ORDERS.parquet\")\n",
    "df_all_content = pd.read_parquet(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\extracted_text_for_AC-ORDER_8300.10-ORDER_8400.10-ORDER_8700.1-ORDER_8740.1-ORDER_8900.1-ORDERS-20231214 - 020735.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non DRS document (AIM...)\n",
    "Defining the functions first and then applying that on a selection of Non DRS documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "\n",
    "# pdf.pages[pdf.get_destination_page_number(pdf.outline[n]):\n",
    "#                             pdf.get_destination_page_number(pdf.outline[n+1])].extract_text()\n",
    "\n",
    "def get_bookmarks(outlines, pdf, parent_position_in_bookmark_tree):\n",
    "    headers = ['position in bookmark tree',\n",
    "                'original pdf bookmark title (outline.title)',\n",
    "                'original pdf bookmark page number'\n",
    "                ]\n",
    "    df_content = pd.DataFrame(columns=headers,\n",
    "                            dtype=\"string\")    \n",
    "    n_section = -1\n",
    "\n",
    "    for outline in outlines:\n",
    "        if type(outline) == PyPDF2.generic._data_structures.Destination:\n",
    "            n_section = n_section + 1\n",
    "            if parent_position_in_bookmark_tree=='':\n",
    "                current_position_in_bookmark_tree = str(n_section)\n",
    "            else:\n",
    "                current_position_in_bookmark_tree = parent_position_in_bookmark_tree+'>'+str(n_section)\n",
    "\n",
    "            bookmark_content = [current_position_in_bookmark_tree,\n",
    "                                outline.title,\n",
    "                                str(pdf.get_destination_page_number(outline))\n",
    "                                ]                        \n",
    "            df_thisbookmark_content = pd.DataFrame(dict(zip(headers, bookmark_content)),\n",
    "                                                dtype=\"string\", \n",
    "                                                index=[0])            \n",
    "            df_content = pd.concat([df_content, \n",
    "                                    df_thisbookmark_content], \n",
    "                                    ignore_index=True)\n",
    "                \n",
    "        elif type(outline) == list:\n",
    "            if parent_position_in_bookmark_tree=='':\n",
    "                current_position_in_bookmark_tree = str(n_section)\n",
    "            else:\n",
    "                current_position_in_bookmark_tree = parent_position_in_bookmark_tree+'>'+str(n_section)\n",
    "\n",
    "            extracted_content = get_bookmarks(outline, pdf, current_position_in_bookmark_tree)\n",
    "\n",
    "            df_content = pd.concat([df_content, \n",
    "                                    extracted_content], \n",
    "                                    ignore_index=True)\n",
    "        \n",
    "    return df_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -> (73, 4)\n",
      "   -> (187, 4)\n",
      "   -> (372, 4)\n",
      "   -> (679, 4)\n",
      "   -> (704, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import datetime\n",
    "\n",
    "raw_documents = glob.glob(os.path.join(os.getcwd(), 'data', 'NotInDRS', 'raw data', 'NotInDRS', 'pdf', '*.pdf'))\n",
    "df_all_content = None\n",
    "\n",
    "for raw_document in raw_documents:\n",
    "    drs_doc = PyPDF2.PdfReader(raw_document)\n",
    "    df_content = get_bookmarks(outlines = drs_doc.outline, pdf = drs_doc, parent_position_in_bookmark_tree='')\n",
    "\n",
    "    if len(df_content)>0:                    \n",
    "        df_content.insert(loc=0, column='filename', value=os.path.basename(raw_document))\n",
    "        if df_all_content is not None:\n",
    "            df_all_content = pd.concat([df_all_content, \n",
    "                                        df_content], \n",
    "                                        ignore_index=True)\n",
    "        else:\n",
    "            df_all_content = df_content\n",
    "        print('   -> '+str(df_all_content.shape))\n",
    "\n",
    "                \n",
    "df_all_content.to_parquet(os.path.join(os.getcwd(), \n",
    "                                       'data', \n",
    "                                       'NotInDRS', \n",
    "                                       'dataset',\n",
    "                                       'extracted_text',\n",
    "                                       'extracted_text_for_DocNotInDRS'+'-'+datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")+'.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-process to split AIP and AIM with one more section level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m pattern_findings \u001b[38;5;241m=\u001b[39m re_pattern\u001b[38;5;241m.\u001b[39mfindall(pdf\u001b[38;5;241m.\u001b[39mpages[n]\u001b[38;5;241m.\u001b[39mextract_text())\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pattern_findings)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern_finding \u001b[38;5;129;01min\u001b[39;00m pattern_findings:\n\u001b[0;32m     42\u001b[0m         first_letter_lower_case \u001b[38;5;241m=\u001b[39m [w[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mislower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m pattern_finding\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m w[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0123456789\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(first_letter_lower_case)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m2\u001b[39m:\n",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m pattern_findings \u001b[38;5;241m=\u001b[39m re_pattern\u001b[38;5;241m.\u001b[39mfindall(pdf\u001b[38;5;241m.\u001b[39mpages[n]\u001b[38;5;241m.\u001b[39mextract_text())\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pattern_findings)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pattern_finding \u001b[38;5;129;01min\u001b[39;00m pattern_findings:\n\u001b[0;32m     42\u001b[0m         first_letter_lower_case \u001b[38;5;241m=\u001b[39m [w[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mislower() \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m pattern_finding\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m w[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0123456789\u001b[39m\u001b[38;5;124m'\u001b[39m)][\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(first_letter_lower_case)\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import datetime\n",
    "# import PyPDF2 import PdfReader\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "predatasets = sorted(glob.glob(os.path.join(os.getcwd(), 'data', 'NotInDRS', 'dataset', 'extracted_text', '*.parquet')), \n",
    "                    key=os.path.getctime, \n",
    "                    reverse=True)\n",
    "predatasets = [val for val in predatasets if '(augmented)' not in val]\n",
    "df_predataset = pd.read_parquet(predatasets[0])\n",
    "\n",
    "filename_aim = 'Aeronautical Information Manual (AIM) Basic with Change 1.pdf'\n",
    "filename_aip = 'Aeronautical Information Publication (AIP) Basic with Amendments 1, 2 and 3.pdf'\n",
    "\n",
    "pdf_aim = PdfReader(os.path.join(os.getcwd(), 'data', 'NotInDRS', 'raw data', 'NotInDRS', 'pdf', filename_aim))\n",
    "pdf_aip = PdfReader(os.path.join(os.getcwd(), 'data', 'NotInDRS', 'raw data', 'NotInDRS', 'pdf', filename_aip))\n",
    "\n",
    "re_prefix = '[ \\s\\r\\n]'\n",
    "re_sufix = '[\\r\\n]'\n",
    "re_pattern_aim = re.compile(re_prefix+\n",
    "                            '[0-9]{1,2}[−-][0-9]{1,2}[−-][0-9]{1,2}\\. [A-Za-z \\(\\)\\-−\\/]{6,80}'+\n",
    "                            re_sufix)\n",
    "re_pattern_aip1 = re.compile(re_prefix+\n",
    "                             '[0-9]{1,2}\\. [A-Za-z \\(\\)\\-−\\/]{6,80}'+\n",
    "                             re_sufix)\n",
    "\n",
    "list_split4nonDRS = [[filename_aim, pdf_aim, re_pattern_aim],\n",
    "                     [filename_aip, pdf_aip, re_pattern_aip1]]\n",
    "\n",
    "for settings in list_split4nonDRS:\n",
    "    filename, pdf, re_pattern = settings\n",
    "    df_tobeadded = pd.DataFrame(columns=['previous_index']+list(df_predataset),\n",
    "                                dtype=\"string\")\n",
    "    for n in range(372, len(pdf.pages)):\n",
    "        pattern_findings = re_pattern.findall(pdf.pages[n].extract_text())\n",
    "        if len(pattern_findings)>0:\n",
    "            for pattern_finding in pattern_findings:\n",
    "                first_letter_lower_case = [w[0].islower() for w in pattern_finding.split(' ') if (len(w)>3 and w[0] not in '0123456789')][1:]\n",
    "                if np.sum(first_letter_lower_case)<2:\n",
    "                    previous_index = df_predataset[(df_predataset[\"filename\"]==filename) & \n",
    "                                                (df_predataset[\"original pdf bookmark page number\"].apply(int)<=n) &\n",
    "                                                (df_predataset[\"original pdf bookmark page number\"].apply(int)>=0)].index[-1]\n",
    "                    df_new_content = pd.DataFrame(dict(zip(['previous_index']+list(df_predataset), \n",
    "                                                            [previous_index,\n",
    "                                                            filename,\n",
    "                                                            df_predataset.loc[previous_index,\"position in bookmark tree\"]+'>0',\n",
    "                                                            pattern_finding[1:-1],\n",
    "                                                            str(n)])),\n",
    "                                                        dtype=\"string\", \n",
    "                                                        index=[0])            \n",
    "                    df_tobeadded = pd.concat([df_tobeadded, \n",
    "                                            df_new_content], \n",
    "                                            ignore_index=True)\n",
    "\n",
    "    counter_next_section = 0\n",
    "\n",
    "    df_tobeadded = df_tobeadded.iloc[::-1]\n",
    "    for idx, row in df_tobeadded.iterrows():\n",
    "        df_predataset = pd.concat([df_predataset.iloc[:int(row['previous_index'])+1+counter_next_section], \n",
    "                                pd.DataFrame(dict(zip(list(df_predataset), row[list(df_predataset)])),\n",
    "                                                dtype=\"string\",\n",
    "                                                index=[0]), \n",
    "                                    df_predataset.iloc[int(row['previous_index'])+1+counter_next_section:]]).reset_index(drop=True)\n",
    "\n",
    "df_predataset.to_parquet(os.path.join(os.getcwd(), \n",
    "                                    'data', \n",
    "                                    'NotInDRS', \n",
    "                                    'dataset',\n",
    "                                    'extracted_text',\n",
    "                                    'extracted_text (augmented)_for_DocNotInDRS'+'-'+datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")+'.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patterns to extract FAA paragraphs\n",
    "\n",
    "* For Useful FAA documents:\n",
    "  * AC: OK\n",
    "\n",
    "  * ADFRAWD: \n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ADFREAD:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ADNPRM:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * AFS_FFS_UPDATEPUB:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * AFS_FOCUS_TEAMS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * AIRCRAFT_MASTER_SCHEDULE:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ALERTS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "ULTS WERE, NO ABNORMAL WEAR DETECTED. THIS ENGINE TT O/H WAS 57 HOURS. NOTE; THERE WAS A\n",
    "SIMILAR FAILURE OF AN OTHER ENGINE OF THIS TYPE JUST 3 MONTHS PRIOR TO THIS ONE, THE TTSOH 123 HRS.\n",
    "WILL UPDATE THIS REPORT WITH A PROBABLE CAUSE AND RECOMMENDATION WHEN MORE INFORMATION\n",
    "AVAILABLE. (K)\n",
    "2007FA0000295 CESSNA\n",
    "CONT\n",
    "BEARING\n",
    "WORN\n",
    "3/20/2007\n",
    "414A\n",
    "TSIO520*\n",
    "TURBOCHARGER\n",
    "FAILURE OF RT TURBOCHARGER SEAL AND CENTER BEARING CAUSED SMOKE OUT OF EXHAUST AND\n",
    "SQUEALING NOISE RESULTING IN THE FLIGHT CREW TO FEATHER PROPELLER AND SHUTDOWN THE ENGINE.\n",
    "CAUSE OF FAILURE DO TO WEAR. (K)\n",
    "FMOR477K\n",
    "CESSNA\n",
    "CONT\n",
    "UPLOCK HOOK\n",
    "DISTORTED\n",
    "4/9/2007\n",
    "414A\n",
    "TSIO520*\n",
    "57412025\n",
    "MLG\n",
    "PILOT R\n",
    "-------------\n",
    "\n",
    "RCRAFT LT THE FACTORY.\n",
    "2007FA0000341 CIRRUS\n",
    "CONT\n",
    "RELAY\n",
    "FAILED\n",
    "4/16/2007\n",
    "SR22\n",
    "IO550N\n",
    "T/E FLAP\n",
    "DURING A TRAINING FLIGHT, THE FLAPS BECAME STUCK IN THE DOWN POSITION. THE AIRCRAFT RETURNED TO\n",
    "THE AIRPORT WITHOUT INCIDENT AND THE AIRCRAFT WAS SENT TO MAINTENANCE FOR TROUBLESHOOTING.\n",
    "MAINTENANCE DISCOVERED THE FLAPS DOWN RELAY FAILED.\n",
    "2007FA0000337 CIRRUS\n",
    "CONT\n",
    "CONTROL SYSTEM\n",
    "OUT OF RIG\n",
    "4/18/2007\n",
    "SR22\n",
    "IO550N\n",
    "AILERON SYS\n",
    "DURI\n",
    "    \n",
    "----------\n",
    "\n",
    "WAS EVIDENT, WITH LITTLE OR NO PATTERN OF HONEYCOMB IN THE ADHESIVE IN/ ON THE INNER\n",
    "SURFACE MATERIAL(S). NO EVIDENCE OF POST PRODUCTION REPAIRS WAS APPARENT. ATL MIDO WILL\n",
    "PROCESS FOR POSSIBLE NON-CONFORMANCE. (K)\n",
    "2007FA0000229 ISRAEL\n",
    "GARRTT\n",
    "VALVE\n",
    "CRACKED\n",
    "3/8/2007\n",
    "1124A\n",
    "TFE731*\n",
    "653014\n",
    "RT LWR FUEL CELL\n",
    "CRACK IN INTERCONNECT VALVE MOTOR HOUSING. FOUND DURING BAG REMOVAL AND REINSTALLATION.\n",
    "CAUSE OF CRACK, UNKNOWN. (K)\n",
    "2007FA0000346 LEAR\n",
    "GARRTT\n",
    "ADC\n",
    "MALFUNCTIONED\n",
    "1/22/2007\n",
    "35A\n",
    "TFE731*\n",
    "702490031304\n",
    "DURING P\n",
    "\n",
    "  * AT_JTA:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * BULLETINS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * CFRFRSFAR:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * CFRFRSFAR:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ELOS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * FAR:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "SECTION:   Sec. 60.25\n",
    "Amendment Number: Initial, Effective Date: 10/30/2006\n",
    "\n",
    "TITLE:   Operation with missing, malfunctioning, or inoperative components.\n",
    "\n",
    "SECTION RULE:   (a) No person may knowingly use or allow the use of or misrepresent the capability of an FSTD for any maneuver, procedure, or task that is to be accomplished to meet training, evaluation, or flight experience requirements of this chapter for flight crewmember certification or qualification when there is a missing, malfunctioning, or inoperative (MMI) component that is required to be present and correctly operate for the satisfactory completion of that maneuver, procedure, or task.\n",
    "(b) Each MMI component as described in paragraph (a) of this section, or any MMI component installed and required to operate correctly to meet the current Statement of Qualification, must be repaired or replaced within 30 calendar days, unless otherwise required or authorized by the NSPM.\n",
    "(c) A list of the current MMI components must be readily available in or adjacent to the FSTD for review by users of the device. Electronic access to this list via an appropriate terminal or display in or adjacent to the FSTD is satisfactory. The discrepancy log may be used to satisfy this requirement provided each currently MMI component is listed in the discrepancy log.\n",
    "\n",
    "NPRM ACTIONS:   Not Applicable.\n",
    "\n",
    "FINAL RULE ACTIONS:   Not Applicable.\n",
    "    \n",
    "  * FSB_REPORTS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * GA_JTA:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * INFO:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "An InFO contains valuable information for operators that should help them meet certain administrative, regulatory,\n",
    "or operational requirements with relatively low urgency or impact on safety.\n",
    "Subject: Air Carrier Safety and Pilot Training (ACSPT) Aviation Rulemaking Committee\n",
    "(ARC) Charter and Report\n",
    "Purpose: This InFO describes where the ACSPT ARC charter and report can be found and\n",
    "where requested responses to the report should be directed.\n",
    "Discussion: The FAA convened the ACSPT ARC to meet the requirements set forth in Section\n",
    "204 of Public Law 111-216. The ACSPT ARC has completed its first report and delivered it to\n",
    "Congress on July 29th, 2011. The ACSPT ARC charter and report may be found at the following\n",
    "link: http://www.faa.gov/about/committees/rulemaking/.\n",
    "The ACSPT ARC is required to produce a second report to be delivered to Congress by July 31st,\n",
    "2012. This report will include prevalence of use of best practices identified in the first report and\n",
    "provide recommendations for legislative or regulatory action. The ACSPT ARC is requesting air\n",
    "carrier industry responses to the report delivered to Congress on July 29, 2011, in order to\n",
    "support the preparation of this second report and asks that all responses are directed to the\n",
    "following e-mail address no later than January 31, 2012: acspt.arc@gmail.com.\n",
    "Contact: Questions or comments regarding this InFO should be directed to the Air\n",
    "Transportation Division, AFS-200, telephone (202) 267-8166. Questions or comments regarding\n",
    "the AC\n",
    "\n",
    "\n",
    "-------------\n",
    "\n",
    "BJECT: Maneuvers Away From Planned Track in Oceanic Airspace.\n",
    "Purpose: To inform aircraft operators of the need for pilots to coordinate with the appropriate\n",
    "air traffic facility when they plan a maneuver away from a cleared route.\n",
    "Background: Improved aircraft tracking and reporting equipment is coming into use both\n",
    "onboard trans-oceanic aircraft and in the air traffic facilities controlling trans-oceanic routes.\n",
    "These new technology applications mean that maneuvers from planned track in excess of\n",
    "standard Strategic Lateral Offset Procedures automatically are reported to air traffic facilities,\n",
    "sometimes before flight crews are able to contact the facility regarding their maneuvering. At\n",
    "present, this can be a problem from a control and airspace coordination standpoint. However, as\n",
    "capacity enhancements, such as reduced aircraft separation, come into use, maneuvers away\n",
    "from track without coordination become a greater concern.\n",
    "Discussion: The trans-oceanic flying environment usually involves long range flying that\n",
    "transits multiple weather systems. It is normal that flight crews would need to maneuver in\n",
    "oceanic airspace for the sake of flight safety, but they are required to coordinate such maneuvers\n",
    "with the appropriate air traffic facility. Oceanic traffic density is increasing, taking advantage of\n",
    "such technology as enhanced navigation, communication, and in particular surveillance. In this\n",
    "environment, coordination with air traffic facilities is increasingly important.\n",
    "Recommended action: Directors of safety, directors of operations (parts 121 and 135), training\n",
    "managers, and pilots should maintain or refresh their awareness of reporting requirements\n",
    "involving maneuv\n",
    "    \n",
    "\n",
    "\n",
    "  * LEGAL_INTERPRETATIONS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * MMEL:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * MMEL_POLICY_LETTERS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * NORSEE:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * NOTICES:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "super bien\n",
    "\n",
    "  * NPRM:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OPSS_GUIDANCE:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDER_8300.10: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDER_8400.10: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDER_8700.1: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDER_8740.1: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDER_8900.1: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * ORDERS: OK\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OSR:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OSWG:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_EFB_CHECKLISTS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_EFB_RESEARCH_REPORTS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_FAA_90_DAY_SAFETY_REVIEW:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_INTERNATIONAL_PUBLICATIONS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_JOB_AIDS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_PS_FEDERAL_AVIATION_ACTS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_PS_HANDBOOKS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * OTHER_RCCB:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "    \n",
    "  * PILOT_QUALIFICATION_CURRICULUM:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * POLICY:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "Summary\n",
    "This policy statement addresses the certification of Title 14 Code of Federal Regulations (CFR)\n",
    "Part 23 aircraft that include a Wireless Local Area Network (WLAN), using Institute of\n",
    "Electrical and Electronics Engineers (IEEE) 802.11 a/b/g/n protocols. More specifically, the\n",
    "policy is to clarify the guidance regarding cabin WLAN equipment installation that creates a\n",
    "Radio Frequency (RF) network and provides connectivity (i.e., internet connection and email\n",
    "services) through access point(s) to users with IEEE 802.11 compliant Portable Electronic\n",
    "Devices (PEDs). The primary concern of the subject WLAN certification is the aircraft systems\n",
    "immunity and compatibility with RF energy from transmitting PEDs (T-PEDs).\n",
    "Current Regulatory and Advisory Material\n",
    "The regulations applicable to the installation of WLAN using IEEE 802.11 protocols are 14 Title\n",
    "CFR §§ 23.1301, 23.1309(a), (b)(1), and 23.1431(b).\n",
    "The following Advisory Circulars (ACs) have guidance that is relevant to WLAN installation:\n",
    " AC 20-168, Certification Guidance for Installation of Non-Essential, Non-Required\n",
    "Aircraft Cabin Systems & Equipment (CS&E)\n",
    " AC 20-164, Designing and Demonstrating Aircraft Tolerance to Portable Electronic\n",
    "Devices\n",
    " AC 23-1309-1E, System Safety Analysis and Assessment for Part 23 Airplanes\n",
    "2\n",
    "Background and Relevant Past Practice\n",
    "1.\n",
    "Past FAA certification projects involving WLAN systems focused on the downlink of\n",
    "information from satellites with limited uplink and transmission from the airplane cabin.\n",
    "The configuration of transmitters and receivers within the cabin was rigorously controlled\n",
    "and qualified to airplane installation standards.\n",
    "2.\n",
    "The current WLAN installation involves the use of several transmitters from various\n",
    "consumer electronic equipment (e.g., laptop/tablet computers, smart phones, etc.) whose\n",
    "transmission specifications and failure modes cannot be rigorously analyzed and tested due\n",
    "to the unregulated use of these devices on an airplane.\n",
    "3.\n",
    "New computer interfaces, networks and data protocols have been developed to use wireless\n",
    "radio-frequency (RF) links to transfer data. This allows communications without hard-\n",
    "wired connections. One approach uses IEEE standard 802.11a/b/g/n, which collectively is\n",
    "known as Wi-Fi, for wireless communication. IEEE 802.11b, g, and n use wideband\n",
    "digital modulation techniques in the 2400 to 2483.5 MHz band. IEEE 802.11a and n uses\n",
    "wideband digital modulation techniques in the 5250 to 5350 MHz and 5470 to 5825 MHz\n",
    "frequency bands. Wireless transmitters using IEEE 802.11a, b. g, or n protocol do not\n",
    "require FCC licenses and are allowed to have 1 watt transmitter power with up to 6 dBi\n",
    "antenna gain, which results in 4 watts Effective Isotropic Radiated Power (EIRP) in the\n",
    "US.\n",
    "4.\n",
    "Safety issues related to the installation and use of the wireless RF system within the\n",
    "airplane include:\n",
    " Potential interference with avionics systems whose failure conditions are\n",
    "classified as major or worse, or any required systems\n",
    " Operation of PED and a wireless RF system which is not fully built to airborne\n",
    "equipment standards\n",
    " Vulnerability of airplane systems to intentional or spurious emission of RF energy\n",
    "5.\n",
    "An issue paper has been used recently to address the certification and compliance concerns\n",
    "related to WLAN installation and RF field strength resulting from PED usage.\n",
    "6.\n",
    "AC 20-164 was published with guidance on demonstrating that aircraft and installed\n",
    "systems are tolerant to potential interference from portable electronic devices.\n",
    "Policy\n",
    "The policy points out the items to be considered, and methods acceptable to the FAA regarding\n",
    "the aircraft toleranc\n",
    "    \n",
    "\n",
    "\n",
    "  * SAFO:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    " ble to air carriers in meeting their statutory duty to provide service with the highest possible degree of safety in the public\n",
    "interest. Besides the specific action recommended in a SAFO, an alternative action may be as effective in addressing the safety\n",
    "issue named in the SAFO.\n",
    "Subject: Title 14 of the Code of Federal Regulations (14 CFR) Part 121 Operators Flap Misconfiguration\n",
    "Events\n",
    "Purpose: This SAFO serves to raise awareness of aircraft misconfigurations on takeoff with an emphasis\n",
    "on flap position.\n",
    "Background: The Aviation Safety Information Analysis and Sharing (ASIAS) program recently\n",
    "concluded an analysis of flap misconfiguration events. This analysis included takeoff attempts with flaps\n",
    "set at zero and flap movement during the takeoff roll.\n",
    "Discussion: The ASIAS analysis indicates that while flap misconfiguration events on takeoff are rare,\n",
    "they do exist. Approximately half of the events for misconfiguration during the takeoff roll resulted in\n",
    "rejected takeoffs. The other takeoffs were continued with the flaps being moved during the takeoff roll.\n",
    "The configuration of the airplane by the flightcrew should be in accordance with the operational\n",
    "checklists. It is imperative that flightcrews exercise discipline in the use and the execution of operational\n",
    "checklists to prevent aircraft misconfigurations on takeoff.\n",
    "Recommended Action: Directors of Operations, Directors of Safety, Program Managers, Directors of\n",
    "Training, Training Center Program Managers, Check Pilots, Training Pilots, Chief Pilots and flightcrews\n",
    "should be familiar with the information contained in this SAFO. They should work together to ensure that\n",
    "the content of this SAFO is emphasized in their training programs to raise awareness among their\n",
    "flightcrews of flap misconfiguration events. This is especially important if procedures are being changed\n",
    "in light of the new Federal Aviation Administration (FAA) de-icing procedures. Operators should review\n",
    "their own Aviation Safety Action Program (ASAP) and Flight Operational Quality Assurance (FOQA)\n",
    "data for flap misconfiguration events. Operators are also reminded to conduct an analysis on any change\n",
    "as part of their Safety Management System (SMS) processes.\n",
    "Contact: Questions   \n",
    "\n",
    "\n",
    "  * SAIB:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * SAS_AXH_DCT:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * SAS_DCT:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "  * SCFINAL:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * SCPROPOSED:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * SFAR:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "  * TSO:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "\n",
    "Subject: Personnel Parachute Assemblies and Components\n",
    "1.\n",
    "PURPOSE. This technical standard order (TSO) is for manufacturers applying for a TSO\n",
    "authorization (TSOA) or letter of design approval (LODA). In it, we the Federal Aviation\n",
    "Administration (FAA), tell you what minimum performance standards (MPS) your personnel\n",
    "parachute assembly and components must first meet for approval and identification with the\n",
    "applicable TSO marking.\n",
    "2.\n",
    "APPLICABILITY. This TSO affects new applications submitted after its effective date.\n",
    "a. All prior revisions to this TSO are no longer effective. Generally, we will not accept\n",
    "applications for the previous revision after the effective date of this TSO. We may do so,\n",
    "however, up to six months after it, if we know that you were working against the prior MPS\n",
    "before the new change became effective.\n",
    "b. Personnel parachute assemblies and components approved under a previous TSOA may\n",
    "still be manufactured under the provisions of its original approval.\n",
    "3. REQUIREMENTS. New models of personnel parachute assemblies and components\n",
    "identified and manufactured on or after the effective date of this TSO must meet the MPS\n",
    "qualification and documentation requirements in Parachute Industry Association (PIA)\n",
    "Technical Standard 135 TS-135 Revision 1.4 issued April 22, 2010 “Performance Standards for\n",
    "Personnel Parachute Assemblies and Components” as modified by appendix 1 of this TSO.\n",
    "a. Functionality. This TSO’s standards apply to equipment intended to be used as a\n",
    "reserve or emergency parachute.\n",
    "b. Failure Condition Classifications.\n",
    "(1) Lose of t\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "g. Deviations. We have provisions for using alternate or equivalent means of compliance\n",
    "with the criteria in the MPS of this TSO. If you invoke these provisions, you must show that\n",
    "your equipment maintains an equivalent level of safety. Apply for a deviation pursuant to Title\n",
    "14 of the Code of Federal Regulations (CFR) 21.618.\n",
    "4.\n",
    "MARKING.\n",
    "a. Mark at least one major component permanently and legibly with all of the information\n",
    "in 14 CFR 45.15(b). Mark each article according to Equipment Class(es) from Table 1 above.\n",
    "b. If the article includes software and/or airborne electronic hardware, then the article part\n",
    "numbering scheme must identify the software and airborne electronic hardware configuration.\n",
    "The part numbering scheme can use separate, unique part numbers for software, hardware, and\n",
    "airborne electronic hardware.\n",
    "c. You may use electronic part marking to identify software or airborne electronic hardware\n",
    "components by embedding the identification within the hardware component itself (using\n",
    "software) rather than marking it on the equipment nameplate. If electronic marking is used, it\n",
    "must be readily access\n",
    "\n",
    "  * UNAPPROVED_PARTS_NOTIFICATIONS:\n",
    "    * REGEX:\n",
    "    * EXAMPLE:\n",
    "\n",
    "  * (6) Training on Records.\n",
    "  * 21. PASSENGER AND CARGO LOADING PROCEDURES. \n",
    "  * (1) Loading, based on aircraft configuration, i.e.,....\n",
    "  * 1. Purpose.\n",
    "  * Purpose: This InFO informs air carriers of the availability of the Department of Transportation’s (DOT) National Aviation Resource Manual for Quarantinable Diseases. \n",
    "  * SUBJECT: DOT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faa-nlp-drs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
