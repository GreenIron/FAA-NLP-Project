{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset on some subsets of DRS data for haystack.deepset.ai\n",
    "Per https://haystack.deepset.ai/tutorials/08_preprocessing, Haystack expects data to be provided as a list of documents in the following dictionary format. See also https://docs.haystack.deepset.ai/docs/document_store\n",
    "need also to store the answer and the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (1725972168.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    'meta': {'name': DOCUMENT_NAME, ...}\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    {\n",
    "        'content': DOCUMENT_TEXT_HERE,\n",
    "        'meta': {'name': DOCUMENT_NAME, ...}\n",
    "    }, ...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import DRS metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "metadata_mapping = pd.read_excel(os.path.join(os.getcwd(),'data','DRS','index','FAA DRS','DRS Document Types Metadata Mapping.xlsx')) # from https://drs.faa.gov/help/helpdetails and https://drs.faa.gov/help/helpdetails\n",
    "\n",
    "doc_types = pd.unique(metadata_mapping.loc[:, \"Document Type Name in API request\"])\n",
    "doc_types = [val for val in doc_types if isinstance(val, str)]\n",
    "\n",
    "common_fields = []\n",
    "for n,doc_type in enumerate(doc_types):\n",
    "    metadata_names = metadata_mapping.loc[metadata_mapping.loc[:, \"Document Type Name in API request\"]==doc_type, \"Metadata Name in API Response \"]\n",
    "\n",
    "    if n>0:\n",
    "        common_fields = list(set(metadata_names) & set(common_fields))\n",
    "    else:\n",
    "        common_fields = list(set(metadata_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset for which it was possible to split paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_types = ['AC',\n",
    "            'ORDER_8300.10',\n",
    "            'ORDER_8400.10',\n",
    "            'ORDER_8700.1',\n",
    "            'ORDER_8740.1',\n",
    "            'ORDER_8900.1',\n",
    "            'ORDERS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drsmeta = None\n",
    "\n",
    "for doc_type in doc_types:\n",
    "    parquet_files = sorted(glob.glob(os.path.join(os.getcwd(),'data', 'DRS', 'index', doc_type+'_202*.parquet')), \n",
    "                        key=os.path.getctime, \n",
    "                        reverse=True)\n",
    "\n",
    "    if len(parquet_files)>0:\n",
    "        this_parquet = pd.read_parquet(parquet_files[0])\n",
    "        this_parquet.insert(0, \n",
    "                            \"doc_type\", \n",
    "                            value=pd.Series(data=doc_type, index=this_parquet.index, dtype=\"string\"))\n",
    "\n",
    "        if df_drsmeta is None:\n",
    "            df_drsmeta = this_parquet\n",
    "        else:\n",
    "            df_drsmeta = pd.concat([this_parquet,\n",
    "                                    df_drsmeta])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import DRS or non-DRS pre-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_type = 'DRS'\n",
    "# source_type = 'NotInDRS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\dataset\\extracted_text\\extracted_text_for_AC-ORDER_8300.10-ORDER_8400.10-ORDER_8700.1-ORDER_8740.1-ORDER_8900.1-ORDERS-20240116 - 100107.parquet\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documentGuid</th>\n",
       "      <th>position in bookmark tree</th>\n",
       "      <th>original pdf bookmark title (outline.title)</th>\n",
       "      <th>original pdf bookmark page number</th>\n",
       "      <th>corrected pdf bookmark page number</th>\n",
       "      <th>extracted title number</th>\n",
       "      <th>extracted title text</th>\n",
       "      <th>first 20 characters after title</th>\n",
       "      <th>nb_keywords for title search</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162603</th>\n",
       "      <td>8DE31491B04A26B886257F410064242C</td>\n",
       "      <td>12&gt;9</td>\n",
       "      <td>Other comments:</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>e</td>\n",
       "      <td>ther comments:</td>\n",
       "      <td>I would like to discuss the a</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162604</th>\n",
       "      <td>8DE31491B04A26B886257F410064242C</td>\n",
       "      <td>12&gt;10</td>\n",
       "      <td>I would like to discuss the above. Please cont...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>I</td>\n",
       "      <td>would like to discuss the above.</td>\n",
       "      <td>Please contact me.  Submitted</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162605</th>\n",
       "      <td>8DE31491B04A26B886257F410064242C</td>\n",
       "      <td>12&gt;11</td>\n",
       "      <td>Submitted by:   Date:</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>e</td>\n",
       "      <td>ubmitted by:</td>\n",
       "      <td>____________________________</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162606</th>\n",
       "      <td>8DE31491B04A26B886257F410064242C</td>\n",
       "      <td>12&gt;12</td>\n",
       "      <td>FTS Telephone Number:   Routing Symbol:</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>T</td>\n",
       "      <td>TS Telephone Number:</td>\n",
       "      <td>_____________________  Routi</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162607</th>\n",
       "      <td>8DE31491B04A26B886257F410064242C</td>\n",
       "      <td>12&gt;13</td>\n",
       "      <td>FAA Form 1320-19 (8-89)</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>AA Form 1</td>\n",
       "      <td>320-19 (8-89)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            documentGuid position in bookmark tree  \\\n",
       "162603  8DE31491B04A26B886257F410064242C                      12>9   \n",
       "162604  8DE31491B04A26B886257F410064242C                     12>10   \n",
       "162605  8DE31491B04A26B886257F410064242C                     12>11   \n",
       "162606  8DE31491B04A26B886257F410064242C                     12>12   \n",
       "162607  8DE31491B04A26B886257F410064242C                     12>13   \n",
       "\n",
       "              original pdf bookmark title (outline.title)  \\\n",
       "162603                                    Other comments:   \n",
       "162604  I would like to discuss the above. Please cont...   \n",
       "162605                              Submitted by:   Date:   \n",
       "162606            FTS Telephone Number:   Routing Symbol:   \n",
       "162607                            FAA Form 1320-19 (8-89)   \n",
       "\n",
       "       original pdf bookmark page number corrected pdf bookmark page number  \\\n",
       "162603                                 9                                  9   \n",
       "162604                                 9                                  9   \n",
       "162605                                 9                                  9   \n",
       "162606                                 9                                  9   \n",
       "162607                                 9                                  9   \n",
       "\n",
       "       extracted title number              extracted title text  \\\n",
       "162603                      e                    ther comments:   \n",
       "162604                     I   would like to discuss the above.   \n",
       "162605                      e                      ubmitted by:   \n",
       "162606                      T              TS Telephone Number:   \n",
       "162607                      A                         AA Form 1   \n",
       "\n",
       "       first 20 characters after title nb_keywords for title search  \n",
       "162603   I would like to discuss the a                            5  \n",
       "162604   Please contact me.  Submitted                            5  \n",
       "162605    ____________________________                            2  \n",
       "162606    _____________________  Routi                            3  \n",
       "162607                 320-19 (8-89) \n",
       "                            5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "predatasets = sorted(glob.glob(os.path.join(os.getcwd(), 'data', source_type, 'dataset', 'extracted_text', '*.parquet')), \n",
    "                      key=os.path.getctime, \n",
    "                      reverse=True)\n",
    "#df_drs = pd.read_parquet(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\data\\DRS\\extracted_text_for_AC-ORDER_8300.10-ORDER_8400.10-ORDER_8700.1-ORDER_8740.1-ORDER_8900.1-ORDERS-20240104 - 010854.parquet\")\n",
    "print(predatasets[0])\n",
    "df_predataset = pd.read_parquet(predatasets[0])\n",
    "\n",
    "df_predataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset that is haystack.deepset friendly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset = pd.merge(df_predataset, df_drsmeta, on='documentGuid', how='inner').dropna(axis=1, how='all')\n",
    "df_dataset.insert(loc=0, column='content', value=pd.Series(df_dataset.shape[0]*[''], dtype=\"string\"))\n",
    "df_dataset.insert(loc=0, column='parents_title_list', value=pd.Series(df_dataset.shape[0]*[''], dtype=\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\pyarrow\\pandas_compat.py:373: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if _pandas_api.is_sparse(col):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparents_title_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_parents_title_list(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition in bookmark tree\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     83\u001b[0m                                                     df_dataset)        \n\u001b[1;32m---> 84\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_textcontent(pdf\u001b[38;5;241m.\u001b[39mpages, \n\u001b[0;32m     85\u001b[0m                                     index, \n\u001b[0;32m     86\u001b[0m                                     df_dataset)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     88\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError with \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     89\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdocumentGuid=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocumentGuid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     90\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mposition in bookmark tree=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition in bookmark tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     91\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtitle=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal pdf bookmark title (outline.title)\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[14], line 84\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparents_title_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_parents_title_list(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition in bookmark tree\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     83\u001b[0m                                                     df_dataset)        \n\u001b[1;32m---> 84\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m get_textcontent(pdf\u001b[38;5;241m.\u001b[39mpages, \n\u001b[0;32m     85\u001b[0m                                     index, \n\u001b[0;32m     86\u001b[0m                                     df_dataset)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     88\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError with \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     89\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mdocumentGuid=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocumentGuid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     90\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mposition in bookmark tree=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition in bookmark tree\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     91\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtitle=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mdf_dataset\u001b[38;5;241m.\u001b[39mloc[index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moriginal pdf bookmark title (outline.title)\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\victor\\anaconda3\\envs\\faa-nlp-drs\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import glob\n",
    "import re\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "logging.basicConfig(filename='94_make_datasets.log', encoding='utf-8',format='%(asctime)s %(message)s', level=logging.INFO)\n",
    "\n",
    "def get_parents_title_list(position_in_bookmark_tree, df_dataset):\n",
    "    parents_title_list = []\n",
    "    parent_title_number_list = position_in_bookmark_tree.split(\">\")\n",
    "\n",
    "    for n in range(1,len(parent_title_number_list)+1):\n",
    "        matching_index = df_dataset[df_dataset[\"position in bookmark tree\"]==\">\".join(parent_title_number_list[0:n])].index[0]        \n",
    "        parents_title_list.append(df_dataset.loc[matching_index, \"original pdf bookmark title (outline.title)\"])  # extracted title text extracted title number\n",
    "        \n",
    "    return str(parents_title_list)\n",
    "\n",
    "\n",
    "def get_textcontent(pages, index, df_dataset):\n",
    "    first_page = int(df_dataset.loc[index, 'corrected pdf bookmark page number'])\n",
    "    try:\n",
    "        last_page = int(df_dataset.loc[index+1, 'corrected pdf bookmark page number'])\n",
    "    except Exception as e:\n",
    "        n=1\n",
    "        while n<40:\n",
    "            n = n+1\n",
    "            if df_dataset.loc[index+n, 'corrected pdf bookmark page number'].isdigit():\n",
    "                last_page = int(df_dataset.loc[index+n, 'corrected pdf bookmark page number'])\n",
    "                logging.info(\"Degraded mode for last_page, use different next index \"+ e.args[0] +\n",
    "                            \"\\ndocumentGuid=\"+df_dataset.loc[index+n, \"documentGuid\"]+\n",
    "                            \"\\nposition in bookmark tree=\"+df_dataset.loc[index+n, \"position in bookmark tree\"]+\n",
    "                            \"\\ntitle=\"+df_dataset.loc[index+n, \"original pdf bookmark title (outline.title)\"])            \n",
    "\n",
    "    textcontent = []\n",
    "\n",
    "    for n in range(first_page, last_page+1):\n",
    "        if n==first_page:\n",
    "            try:\n",
    "                re_search = re.search(re.escape(df_dataset.loc[index, 'first 20 characters after title']), \n",
    "                                    pages[n].extract_text())\n",
    "                start_textcontent = re_search.span()[0]\n",
    "            except Exception as e:\n",
    "                logging.info(\"Error identifying start_textcontent with \"+ e.args[0] +\n",
    "                             \"\\ndocumentGuid=\"+df_dataset.loc[index, \"documentGuid\"]+\n",
    "                             \"\\nfirst_page=\"+str(first_page)+\n",
    "                             \"\\nposition in bookmark tree=\"+df_dataset.loc[index, \"position in bookmark tree\"]+\n",
    "                             \"\\ntitle=\"+df_dataset.loc[index, \"original pdf bookmark title (outline.title)\"])\n",
    "                start_textcontent = 0\n",
    "        else:\n",
    "            start_textcontent = 0\n",
    "\n",
    "        if n==last_page:\n",
    "            try:\n",
    "                re_search = re.search(re.escape(df_dataset.loc[index+1, 'extracted title number'])+\n",
    "                                    '.{0,5}'+\n",
    "                                    re.escape(df_dataset.loc[index+1, 'extracted title text']), \n",
    "                                    pages[n].extract_text())                                    \n",
    "                end_textcontent = re_search.span()[0]\n",
    "            except Exception as e:\n",
    "                logging.info(\"Error identifying end_textcontent with \"+ e.args[0] +\n",
    "                             \"\\ndocumentGuid=\"+df_dataset.loc[index, \"documentGuid\"]+\n",
    "                             \"\\nlast_page=\"+str(last_page)+\n",
    "                             \"\\nposition in bookmark tree=\"+df_dataset.loc[index, \"position in bookmark tree\"]+\n",
    "                             \"\\ntitle=\"+df_dataset.loc[index, \"original pdf bookmark title (outline.title)\"])\n",
    "                end_textcontent = None\n",
    "        else:\n",
    "            end_textcontent = None\n",
    "\n",
    "        textcontent.append(pages[n].extract_text()[start_textcontent:end_textcontent])\n",
    "    \n",
    "    return textcontent\n",
    "\n",
    "\n",
    "for index, row in df_dataset.iterrows():\n",
    "    matching_file = glob.glob(os.path.join(os.getcwd(), 'data', source_type, 'raw data', row[\"doc_type\"], 'pdf','*'+row['documentGuid']+'*.pdf'))\n",
    "    if (len(matching_file)>0) and (row['drs:status']=='Current'):\n",
    "        pdf = PyPDF2.PdfReader(matching_file[0])\n",
    "        df_dataset_filtered = df_dataset[df_dataset[\"documentGuid\"]==row[\"documentGuid\"]]\n",
    "\n",
    "        try:\n",
    "            df_dataset.at[index, 'parents_title_list'] = get_parents_title_list(row[\"position in bookmark tree\"],\n",
    "                                                            df_dataset)        \n",
    "            df_dataset.at[index, 'content'] = get_textcontent(pdf.pages, \n",
    "                                            index, \n",
    "                                            df_dataset)\n",
    "        except Exception as e:\n",
    "            logging.info(\"Error with \"+ e.args[0] +\n",
    "                         \"\\ndocumentGuid=\"+df_dataset.loc[index, \"documentGuid\"]+\n",
    "                         \"\\nposition in bookmark tree=\"+df_dataset.loc[index, \"position in bookmark tree\"]+\n",
    "                         \"\\ntitle=\"+df_dataset.loc[index, \"original pdf bookmark title (outline.title)\"])\n",
    "            \n",
    "    if index % 50000==0:\n",
    "        df_dataset.to_parquet(os.path.join(os.getcwd(),\n",
    "                                    'data', \n",
    "                                    source_type, \n",
    "                                    'dataset (partial'+str(index)+')_for_'+'-'.join(doc_types)+'-'+datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")+'.parquet'))\n",
    "\n",
    "\n",
    "df_dataset.to_parquet(os.path.join(os.getcwd(),\n",
    "                                   'data', \n",
    "                                   source_type, \n",
    "                                   'dataset_for_'+'-'.join(doc_types)+'-'+datetime.datetime.now().strftime(\"%Y%m%d - %H%M%S\")+'.parquet'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some metric\n",
    "Number of documents total, number of documents per entry, histogram of number of words total, histogram of doc per doc type, nombre de doc pas dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to find patterns in df_dataset for debugging/improviong the 92_split functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c49a9e6d6b122d0bc46f085b0f9b84866f77188fdff3252b8a9eae176833897"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
