{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77661, 26)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_stc = pd.read_excel(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\stc.xlsx\")\n",
    "df_stc = df_stc.drop_duplicates()\n",
    "df_stc['drs:stcHolder'] = df_stc['drs:stcHolder'].map(lambda x: x.replace(\", Inc.\",\"\").replace(\", Inc\",\"\").replace(\" Inc.\",\"\").replace(\" Inc\",\"\"))\n",
    "\n",
    "print(df_stc.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the STC with fields that get incorrectly decoded\n",
    "TODO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode STCs text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_block(text, pattern_start, pattern_end):\n",
    "    try:\n",
    "        match_start = re.search(pattern_start, text, re.IGNORECASE)\n",
    "        match_end = re.search(pattern_end, text[match_start.span(0)[1]:], re.IGNORECASE)\n",
    "\n",
    "        return text[match_start.span(0)[1]:(match_end.span(0)[0]+match_start.span(0)[1])]\n",
    "    except:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_all_descriptions(pdf_pages):\n",
    "    descriptions = []\n",
    "\n",
    "    # First page\n",
    "    descriptions.append(get_block(pdf_pages[0],\n",
    "                                  '(\\n|\\n\\r|\\r|\\(| )Description of (the )?Type Design Change:?\\.?(\\n|\\n\\r|\\r|\\)| )',\n",
    "                                  '(Limitations |[a-z ]{5,10}ions and Cond|\\(Description |\\(See continuation)'))\n",
    "    # Other pages\n",
    "    final_del = '- - -|\\. \\. \\. |\\* \\* \\* |END|---|\\.\\.\\.|\\*\\*\\*|Certification Basis|Certification Basis|\\(See continuation|\\(cont'\n",
    "    for n in range(1, len(pdf_pages)):\n",
    "        descriptions.append(get_block(pdf_pages[n],\n",
    "                                      '(\\n|\\n\\r|\\r|\\(| )Description of (the )?Type Design Change:?\\.? (\\(con[a-z ]+\\)|con[a-z ]+):?(\\n|\\n\\r|\\r|\\)| )',\n",
    "                                      '(\\n|\\n\\r|\\r|\\(| )(Limitations and Conditions (\\(con[a-z ]+\\)|con[a-z ]+):'+'|'+final_del+')'))\n",
    "        \n",
    "\n",
    "    return descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_all_limitations(pdf_pages):\n",
    "    limitations = []\n",
    "\n",
    "    # First page\n",
    "    limitations.append(get_block(pdf_pages[0],\n",
    "                                  '(\\n|\\n\\r|\\r)(Limitations and Conditions|[a-z ]{5,10}ions and Cond[a-z ]{5,10}):?\\.?(\\n|\\n\\r|\\r| )',\n",
    "                                  '(\\(Limitations |(\\n|\\n\\r|\\r)This certificat|\\(See )'))\n",
    "    # Other pages     \n",
    "    final_del = '---|\\.\\.\\.|\\*\\*\\*|Certification Basis|Certification Basis|\\(See continuation|\\(cont'\n",
    "    for n in range(1, len(pdf_pages)):\n",
    "        final_del = '- - -|\\. \\. \\. |\\* \\* \\* |---|\\.\\.\\.|\\*\\*\\*|Certification Basis|Certification Basis|\\(See continuation|\\(cont'\n",
    "        limitations.append(get_block(pdf_pages[n],\n",
    "                                      '(\\n|\\n\\r|\\r|\\(| )Limitations and Conditions:?\\.? (\\(con[a-z ]+\\)|con[a-z ]+):?(\\n|\\n\\r|\\r|\\)| )', \n",
    "                                      \"(\\n|\\n\\r|\\r|\\(| )(\"+final_del+\")\"))\n",
    "    return limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_limitations(text):\n",
    "    split_text = re.split('(\\\\n|\\s)[1]{0,1}[0-9]\\.\\s', text)\n",
    "    split_text = [re.sub('\\n', ' ', val) for val in split_text if len(val)>5]\n",
    "    return split_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example to decode stc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "=======================\n",
      "['Data pertaining to this modification are considered inadequate for\\nduplication in other aircraft. This approval is therefore limited to the installation in Waco UKC airplane\\nserial number 3978, registration N14611 only. A copy of this certificate, and the Airplane Flight Manual\\nSupplement dated March 31, 2006 shall be maintained as part of the permanent records for the\\nmodified aircraft.\\n']\n",
      "=======================\n",
      "['UnitedStatesofAmerica\\nDepartmentofTransportation_FederalAviationAdministration\\nSupplementalTypeCertificate\\nNumber\\nSA01661SE\\nThis certificate, issued to Olde Thyme Aviation\\n21704 141st Ave. SW\\nVashon Island, WA 98070\\ncertifies that the change in the type design for the following product with the limitations and conditions\\ntherefor as specified hereon meets the airworthiness requirements of Type Certificate ATC 528.\\nOriginal Product\\uf0beType Certificate Number: ATC 528\\nMake: Waco\\nModel: UKC\\nDescription of the Type Design Change: Install a Continental W670-23 engine in the above model\\nairplane in accordance with Olde Thyme Aviation Pictures 1 through 36, and Olde Thyme Aviation\\nInstallation Report OTA-3-1-06 dated March 20, 2006.\\nLimitations and Conditions: Data pertaining to this modification are considered inadequate for\\nduplication in other aircraft. This approval is therefore limited to the installation in Waco UKC airplane\\nserial number 3978, registration N14611 only. A copy of this certificate, and the Airplane Flight Manual\\nSupplement dated March 31, 2006 shall be maintained as part of the permanent records for the\\nmodified aircraft.\\nThis certificate and the supporting data which is the basis for approval shall remain in effect until sur-\\nrendered, suspended, revoked, or a termination date is otherwise established by the Administrator of the\\nFederal Aviation Administration.\\nDate of application: November 6, 2003 Date reissued:\\nDate of issuance: March 31, 2006 Date amended:\\nBy direction of the Administrator\\n__________________________________________\\n(Signature)\\nActing Manager, Seattle Aircraft\\nCertification Office\\n(Title)\\nAny alteration of this certificate is punishable by a fine of not exceeding $1,000, or imprisonment not exceeding 3 years, or both.\\nThis certificate may be transferred in accordance with FAR 21.47.\\nFAA FORM 8110-2(10-68)\\n']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSR00592DE__Current__1331A416DAE36E99862588A7004BFFD0\\nSA1771CE-D__Current__84229556CA57EA138625861E007A36C9\\nSA2196CE__Current__36F896ABA7701168862585180058641A\\n\\nST04436AT (2 OF 2)__Current__8C9E2E584973558B86258876006E8DB7\\n\\nSR03913NY__Current__C9692170F9AEC5C6862585EC00565F13\\n\\nSA760CE__Historical__262337959FF88250862572C70055A8F3\\n\\nST02184LA-D__Current__8A332D420524BE9F862575FC006B4BAF\\n\\nSA01661SE__Current__7F91E1600D295CEF8625715400581B6B\\n'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "with pdfplumber.open(r'C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\pdf\\SA01661SE__Current__7F91E1600D295CEF8625715400581B6B.pdf') as pdf:\n",
    "    pdf_pages = [str(this_page.extract_text())+'\\n' for this_page in pdf.pages]\n",
    "\n",
    "    print(get_all_descriptions(pdf_pages))\n",
    "    print(\"=======================\")\n",
    "    print(get_all_limitations(pdf_pages))\n",
    "    print(\"=======================\")\n",
    "    print(pdf_pages)\n",
    "\n",
    "'''\n",
    "SA00001SE__Historical__7B567CD4F182FBDB85256CC1007DC6F6\n",
    "\n",
    "SR00592DE__Current__1331A416DAE36E99862588A7004BFFD0\n",
    "SA1771CE-D__Current__84229556CA57EA138625861E007A36C9\n",
    "SA2196CE__Current__36F896ABA7701168862585180058641A\n",
    "\n",
    "ST04436AT (2 OF 2)__Current__8C9E2E584973558B86258876006E8DB7\n",
    "\n",
    "SR03913NY__Current__C9692170F9AEC5C6862585EC00565F13\n",
    "\n",
    "SA760CE__Historical__262337959FF88250862572C70055A8F3\n",
    "\n",
    "ST02184LA-D__Current__8A332D420524BE9F862575FC006B4BAF\n",
    "\n",
    "SA01661SE__Current__7F91E1600D295CEF8625715400581B6B\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Installation of a L3 Communciations Cockpit Voice and Flight Data Recorder (CVDR) in accordance with FAA\\napproved ARINC Master Data List, Document No. 74-2370X001 Revision “A”, dated July 16, 2009 or later FAA\\napproved revisions.\\n']\n",
      "=======================\n",
      "['2.\\n1. Compatibility of this design change with previously approved modifications must be determined by installer.\\nInstructions for Continued Airworthiness, Document 74-2370C001 entitled: \"Viking DHC-6-300 Twin Otter\\nCockpit Voice / Data Recorder Instructions for Continued Airworthiness\", Revision A, dated July 8, 2009, or\\nlater FAA accepted revision is required for this installation.\\n3.\\nIf the holder agrees to permit another person to use this certificate to alter the product, the holder shall give\\nthe other person written evidence of the permission.\\n4.\\nA copy of this certificate and FAA approved Airplane Flight Manual Supplement, Document 74-2370A001,\\nRevision IR, dated July 16, 2009 or later FAA approved revision for the Cockpit Voice / Data Recorder\\nSystem installation must be maintained as part of the permanent records of the modified aircraft.\\nDate of application:\\nDate of issuance:']\n",
      "=======================\n",
      "['United States of America\\nDepartment of Transportation-Federal Aviation Administration\\nSupplemental Type Certificate\\nNumber SA00027MC-D\\nThis certificate, issued to\\nARINC, Inc.\\n1925 Aerotech Drive, Suite 212\\nColorado Springs, CO 80916\\ncertifies that the change in the type design for the following product with the limitations and conditions\\ntherefor as specified hereon meets the airworthiness requirements of Part 23* of the Federal Aviation\\nRegulations. *(For certification basis T.C. Data Sheet A9EA)\\nOriginal Product Type Certificate Number: A9EA\\nMake:\\nModel:\\nDescription of the Type Design Change:\\nInstallation of a L3 Communciations Cockpit Voice and Flight Data Recorder (CVDR) in accordance with FAA\\napproved ARINC Master Data List, Document No. 74-2370X001 Revision “A”, dated July 16, 2009 or later FAA\\napproved revisions.\\nLimitations and Conditions:\\n2.\\n1. Compatibility of this design change with previously approved modifications must be determined by installer.\\nInstructions for Continued Airworthiness, Document 74-2370C001 entitled: \"Viking DHC-6-300 Twin Otter\\nCockpit Voice / Data Recorder Instructions for Continued Airworthiness\", Revision A, dated July 8, 2009, or\\nlater FAA accepted revision is required for this installation.\\n3.\\nIf the holder agrees to permit another person to use this certificate to alter the product, the holder shall give\\nthe other person written evidence of the permission.\\n4.\\nA copy of this certificate and FAA approved Airplane Flight Manual Supplement, Document 74-2370A001,\\nRevision IR, dated July 16, 2009 or later FAA approved revision for the Cockpit Voice / Data Recorder\\nSystem installation must be maintained as part of the permanent records of the modified aircraft.\\nDate of application:\\nDate of issuance:\\nThis certificats and the supporting data which is the basis for approval shall remain in effect until sur-\\nrendered, suspended, revoked, or a termination date is otherwise established by the Administrator of the\\nFederal Aviation Administration.\\nViking Air Limited\\nDHC-6-300\\nFEDERAL\\nFebruary 13, 2009\\nJuly 16, 2009\\nAVIATION\\nADMINISTRATION\\nDate reissued:\\nDate amended:\\nBy direction of the Administrator\\nJohn May\\n(Signature)\\nJohn May\\nODA administrator\\nODA 636304-NM, ARINC, Inc.\\n(Title)\\nAny alteration of this certificate is punishable by a fine of not exceeding $1,000, or imprisonment not exceeding 3 years, or\\nboth.\\nFAA Form 8110-2(10-68)\\nThis certificate may be transferred in accordance with FAR 21.47.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nSA00001SE__Historical__7B567CD4F182FBDB85256CC1007DC6F6\\n\\nSR00592DE__Current__1331A416DAE36E99862588A7004BFFD0\\nSA1771CE-D__Current__84229556CA57EA138625861E007A36C9\\nSA2196CE__Current__36F896ABA7701168862585180058641A\\n\\nST04436AT (2 OF 2)__Current__8C9E2E584973558B86258876006E8DB7\\n\\nSR03913NY__Current__C9692170F9AEC5C6862585EC00565F13\\n\\nSA760CE__Historical__262337959FF88250862572C70055A8F3\\n\\nST02184LA-D__Current__8A332D420524BE9F862575FC006B4BAF\\n\\nSA01661SE__Current__7F91E1600D295CEF8625715400581B6B\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r\"C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\text-from-pdf\\SA00027MC-D__Current__AB80219E04E9EC478625762000544966.txt\",\"r\") as my_text:\n",
    "    pdf_pages = my_text.read().split(\"\\n\\n\")\n",
    "\n",
    "    print(get_all_descriptions(pdf_pages))\n",
    "    print(\"=======================\")\n",
    "    print(get_all_limitations(pdf_pages))\n",
    "    print(\"=======================\")\n",
    "    print(pdf_pages)\n",
    "\n",
    "'''\n",
    "SA00001SE__Historical__7B567CD4F182FBDB85256CC1007DC6F6\n",
    "\n",
    "SR00592DE__Current__1331A416DAE36E99862588A7004BFFD0\n",
    "SA1771CE-D__Current__84229556CA57EA138625861E007A36C9\n",
    "SA2196CE__Current__36F896ABA7701168862585180058641A\n",
    "\n",
    "ST04436AT (2 OF 2)__Current__8C9E2E584973558B86258876006E8DB7\n",
    "\n",
    "SR03913NY__Current__C9692170F9AEC5C6862585EC00565F13\n",
    "\n",
    "SA760CE__Historical__262337959FF88250862572C70055A8F3\n",
    "\n",
    "ST02184LA-D__Current__8A332D420524BE9F862575FC006B4BAF\n",
    "\n",
    "SA01661SE__Current__7F91E1600D295CEF8625715400581B6B\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract texts to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "dl_dir = r'C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\pdf'\n",
    "\n",
    "list_of_real_pdfs = [val for val in glob.glob(os.path.join(dl_dir,\"*.pdf\")) if os.path.getsize(val)>200]\n",
    "pdf_content = [[]]\n",
    "\n",
    "for n, pdf in enumerate(list_of_real_pdfs):\n",
    "    split_name = os.path.basename(pdf[:-4]).split(\"__\")\n",
    "\n",
    "    try:\n",
    "        with pdfplumber.open(pdf) as opened_pdf:        \n",
    "            pdf_pages = [str(this_page.extract_text())+'\\n' for this_page in opened_pdf.pages]\n",
    "\n",
    "            pdf_content.append([split_name[0],\n",
    "                                split_name[1],\n",
    "                                split_name[2],\n",
    "                                get_all_descriptions(pdf_pages),\n",
    "                                get_all_limitations(pdf_pages),\n",
    "                                df_stc[df_stc[\"documentGuid\"]==split_name[2]][\"drs:title\"].values[0],\n",
    "                                df_stc[df_stc[\"documentGuid\"]==split_name[2]][\"drs:stcAplicationDate\"]])\n",
    "            \n",
    "        break\n",
    "\n",
    "    except:\n",
    "        print(pdf)\n",
    "\n",
    "df_pdf_content = pd.DataFrame(pdf_content,\n",
    "                            columns=[\"drs:chronicleId\",\n",
    "                                    \"drs:status\",\n",
    "                                    \"documentGuid\",\n",
    "                                    \"description\",\n",
    "                                    \"limitation\",\n",
    "                                    \"drs:title\",\n",
    "                                    \"drs:stcAplicationDate\"])    \n",
    "\n",
    "df_pdf_content.to_excel('pdfs_with_content.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "dl_dir = r'C:\\Users\\victor\\Documents\\DeepLearning\\FAA NLP Project\\database\\data\\stc\\text-from-pdf'\n",
    "\n",
    "list_of_real_pdfs = [val for val in glob.glob(os.path.join(dl_dir,\"*.txt\")) if os.path.getsize(val)>0]\n",
    "pdf_content = [[]]\n",
    "\n",
    "for n, file in enumerate(list_of_real_pdfs):\n",
    "    split_name = os.path.basename(file[:-4]).split(\"__\")\n",
    "\n",
    "    try:\n",
    "        with open(file,\"r\") as my_text:\n",
    "            pdf_pages = my_text.read().split(\"\\n\\n\")\n",
    "\n",
    "            pdf_content.append([split_name[0],\n",
    "                                split_name[1],\n",
    "                                split_name[2],\n",
    "                                get_all_descriptions(pdf_pages),\n",
    "                                get_all_limitations(pdf_pages),\n",
    "                                df_stc[df_stc[\"documentGuid\"]==split_name[2]][\"drs:title\"].values[0],\n",
    "                                df_stc[df_stc[\"documentGuid\"]==split_name[2]][\"drs:stcAplicationDate\"]])\n",
    "            \n",
    "        if n>400000:    \n",
    "            break\n",
    "\n",
    "    except:\n",
    "        print(file)\n",
    "\n",
    "df_pdf_content = pd.DataFrame(pdf_content,\n",
    "                            columns=[\"drs:chronicleId\",\n",
    "                                    \"drs:status\",\n",
    "                                    \"documentGuid\",\n",
    "                                    \"description\",\n",
    "                                    \"limitation\",\n",
    "                                    \"drs:title\",\n",
    "                                    \"drs:stcAplicationDate\"])    \n",
    "\n",
    "df_pdf_content = df_pdf_content.tail(-1)\n",
    "\n",
    "df_pdf_content.to_excel('pdfs_with_content.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2ee67a29ab3f291387b20fba2c7efbd6d01be28377ec78ccf2d5038afb76c89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
